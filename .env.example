# =============================================================================
# Instagram Scraper API - Environment Configuration
# =============================================================================

# -----------------------------------------------------------------------------
# Server Configuration
# -----------------------------------------------------------------------------
PORT=3000
NODE_ENV=development

# -----------------------------------------------------------------------------
# Instagram Accounts (Account Rotation System)
# -----------------------------------------------------------------------------
# Format: IG_ACCOUNT_<N>=username:password
# The system will automatically select accounts based on scraping load
# Add as many accounts as needed (numbered sequentially: 1, 2, 3, ...)

IG_ACCOUNT_1=tu_usuario1:tu_password1
IG_PROXY_1=http://usuario_proxy:password_proxy@us.proxy.com:8080 (Opcional)

IG_ACCOUNT_2=tu_usuario2:tu_password2
# IG_PROXY_2=socks5://usuario:password@de.proxy.com:1080

# IG_ACCOUNT_3=tu_usuario3:tu_password3

# -----------------------------------------------------------------------------
# Browser Configuration
# -----------------------------------------------------------------------------
# IMPORTANTE:
# - Desarrollo local: HEADLESS=false (para ver el navegador)
# - Docker/Producción: HEADLESS=true (forzado automáticamente en docker-compose)

HEADLESS=false

# Enable verbose logging (true para desarrollo, false para producción)
VERBOSE_LOGS=true

# Path to Chrome executable (auto-detected if not specified)
# CHROME_PATH=/usr/bin/google-chrome-stable

# -----------------------------------------------------------------------------
# Scraper Configuration
# -----------------------------------------------------------------------------
# Maximum number of posts to scrape per request (default: 12).
# This value is used when 'maxPosts' is not provided in the API request.
# The API scrolls progressively to load more posts until reaching this limit.
MAX_POSTS_PER_REQUEST=12

# Scraper timeout in milliseconds (default: 120000 = 2 minutes)
SCRAPER_TIMEOUT_MS=120000

# Number of concurrent browser tabs for scraping (1-5)
SCRAPER_CONCURRENCY=3

# -----------------------------------------------------------------------------
# Data Persistence
# -----------------------------------------------------------------------------
# Root directory for browser sessions
SESSIONS_ROOT_DIR=sessions

# Root directory for application data (cache, logs, etc.)
DATA_ROOT_DIR=data

# -----------------------------------------------------------------------------
# API Security (Optional)
# -----------------------------------------------------------------------------
# API Key for authentication (optional, leave empty to disable)
# API_KEY=your_secret_api_key_here

# Allowed origins for CORS (comma-separated)
# CORS_ORIGINS=http://localhost:3001,http://localhost:4000

# -----------------------------------------------------------------------------
# Docker Environment
# -----------------------------------------------------------------------------
# NOTA: En producción con Docker, estas variables se sobrescriben automáticamente:
#   - HEADLESS=true (forzado en docker-compose.yml)
#   - DOCKER_ENV=true (forzado en docker-compose.yml)
#
# Usa 'yarn dev' para desarrollo local (HEADLESS=false)
# Usa 'docker-compose up -d' para producción (HEADLESS=true automático)

# -----------------------------------------------------------------------------
# Timezone Configuration
# -----------------------------------------------------------------------------
# Zona horaria para logs (default: America/Guayaquil)
# Ver lista completa: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
TZ=America/Guayaquil
